\Week{2}{Method of Conditional Expectation}


\section{{\sc Maxcut} Problem}

For an undirected graph $G(V,E)$, a cut is a partition of vertices into two sets $S,T \subseteq V$. The size of a cut is the number of edges that go across these partitions. That is, the size of the set :
$$cut(S,T) = \{ e=(u,v) \mid (u,v) \in E, u \in S, v \in T \}$$

Maximum cut is a cut whose size is at least the size of any other cut. That is $|cut(S,T)|$ is the largest possible. Given a graph, the problem of finding a maximum cut in a graph is known as the {\sc Maxcut} problem.

\paragraph*{The problem is hard:} The {\sc Maxcut} problem is known to be $\NP$-hard. This implies, in particular, that if we have an efficient algorithm for the {\sc MaxCut} problem, then some of the very hard problems will yield to having efficient algorithms solving them. This is believed to be unlikely. \\[-9mm]

\paragraph*{Approximation algorithms: }Hence it makes sense to talk about algorithms which may not output the exact maximum cut, but instead another cut. Indeed, this is useless unless there are guaranteed how large is the cut output by the algorithm. An example guarantee that we may want to target is, for the algorithm, no matter what the input graph $G$ is, the cut output by the algorithm will be, say, at least $\left(\frac{1}{10}\right)$-th of the size of the maximum cut. This is called a $0.1$-approximation algorithm\footnote{Exercise: if you have not seen it already, think about what would be a similar statement that you would like to target for a minimization problem, like vertex cover problem}. Even with this relaxed target for the algorithm, is not immediately clear how to design such an algorithm. It turns out that the best known algorithm for {\sc Maxcut} does much better than this and achieves an approximation guarantee of $0.875$, and for many reasons this is believed to be the best possible ratio that any polynomial time algorithm can achieve for {\sc Maxcut} problem. However, in this lecture, we will concentrate on much smaller rations. \\[-9mm]

\paragraph*{Randomized Approximation algorithms: }
We resort to randomized algorithms - which in this context will be called randomized approximation algorithms. Notice that unlike the previous examples, {\sc Maxcut} is not a decision problem. Hence, we need to be careful about designing and analysing randomized algorithms for it. For example, there is nothing like the algorithm being correct. Instead, we have only the notion of the approximation ratio - that is how close the output of the algorithm is, to the optimal value.

\subsection{A Simple Randomized Algorithm} We start with a simple randomized algorithm for {\sc MaxCut} problem.

\begin{algorithm}%\captionsetup{labelfont={sc,bf},labelsep=newline}
\label{alg:maxcut-rand}
\caption{: Randomized Approx. Algorithm for {\sc MaxCut} for graph $G(V,E)$, $|V| = n$}
\begin{algorithmic}[1]
\State $S = T = \phi$
\For{each $i \in [n]$}
\State Choose bit $b_i \in \{0,1\}$ uniformly at random.
\If{$b_i = 1$}
\State $S = S \cup \{i\}$
\Else
\State $T = T \cup \{i\}$.
\EndIf
\EndFor
\State Output $cut(S,T)$.
\end{algorithmic}
\end{algorithm}

Notice that the sets $S$ and $T$ will form a partition of $V$ at the end of the algorithm. Clearly, the algorithm will run in linear time. Indeed, the above description is also equivalent to - choose a random subset $S$ of vertices from $V$ and outputing $cut(S,\overline{S})$. Indeed, we need to give a guarantee about the size of the cut output by the algorithm. Roughly, the claim is that the average size of the cut (where average is taken over the $2^n$ different outcomes of the random choices). We recap some basics of random variables and expections now before stating the correctness claim.

\section{Recap of Probability Basics, Random Variables, Expectation}

Fix a set $\Omega$, which is called the {\em sample space}.
A probability distribution is defined over $\Omega$, is a function $\Pr: \Omega \to [0,1]$ satisfying the additional condition that, $\sum_{w \in \Omega} \Pr(w) = 1$. An event is a subset ${\cal{E}} \subseteq \Omega$. The probability of an even $\cal{E}$ is nothing buy the sum of the probability values by assigned by the distribution functon to the elements in the subset $\cal{E}$. That is, $\Pr({\cal{E}}) = \sum_{w \in E} \Pr(w)$.

We consider an example which are going to be relevant for us. This is the notion of random graphs. Consider $n$ vertices, and there are ${n \choose 2}$ possible edges. Imagine that we will choose (independently) each edge to be present in our graph with probability $p$ and to be absent in our graph with probability. The outcome of the experiment is an $n$-vertex simple graph and hence the sample space is the set of all $n$ vertex graphs.

As an example, we can consider, $n=3$. There are $3$ possible edges and hence $8$ possible graphs. The probability assigned the triangle graph (which is the complete graph on $3$ vertices) is $p^3$ since all the three edges have to be chosen for this particular outcome to happen. In a similar way, the following pictures denote the sample space in this case with the corresponding probability values.\\

\begin{center}
\begin{tikzpicture}
\path[draw] (2,2)node(){$\circ$} -- (3,3)node(){$\circ$} -- (4,2)node(a){$\circ$} -- cycle;
\path[draw] (5,2)node(){$\circ$} -- (6,3)node(){$\circ$}--(7,2)node(){$\circ$};
\path[draw] (8,2)node(){$\circ$} -- (10,2)node(){$\circ$}--(9,3)node(){$\circ$};  
\path[draw] (13,2)node(){$\circ$}--(12,3)node(){$\circ$} -- (11,2)node(){$\circ$};  
\path[draw] (2,0)node(){$\circ$} -- (3,1)node(){$\circ$}(4,0)node(){$\circ$};
\path[draw] (5,0)node(){$\circ$} -- (7,0)node(){$\circ$}(6,1)node(){$\circ$};
\path[draw] (10,0)node(){$\circ$} -- (9,1)node(){$\circ$}(8,0)node(){$\circ$};
\path[draw] (11,0)node(){$\circ$} (12,1)node(){$\circ$}(13,0)node(){$\circ$};
\end{tikzpicture}
\end{center}

\noindent The probabilities in that order are $p^3$, $p^2(1-p)$, $p^2(1-p)$, $p^2(1-p)$, $p(1-p)^2$, $p(1-p)^2$, $p(1-p)^2$, $(1-p)^3$.

How do we analyse the probability that we get a connected graph as the outcome of the experiment. This is where events are used. Recall that formally, an event $\cal{E}$ is a subset of $\Omega$.

$$Pr({\cal{E}}) = \sum_{w \in {\cal{E}}} Pr(w)$$

\noindent In the above example, if the event ${\cal{E}}$ represent the set of connected graphs.

$$Pr({\cal{E}}) = p^3+2p^2(1-p)$$

\noindent In the above example, if the event ${\cal{E}'}$ represent the set of bipartite graphs.

$$Pr({\cal{E}'}) = 1-p^3$$

\begin{proposition}[{\bf Subadditivity of Probability - a.k.a - Union theorem}]
Let ${\cal{E}}_1$,${\cal{E}}_2 \ldots {\cal{E}}_n$ be events, then :
$$Pr\left[\bigcup_{i} {\cal{E}}_i\right] \le \sum_{i=1}^n Pr[{\cal{E}}_i]$$
\end{proposition}

\begin{definition}[{\bf Conditional Probability}]
For two events ${\cal{E}}$ and ${\cal{E}'}$, we define, 
$$Pr({\cal{E}}|{\cal{E}'}) = \frac{Pr({\cal{E}}\cap{\cal{E}'})}{Pr({\cal{E}'})}$$
\end{definition}

\noindent The conditional probability captures the questions of the kind, what is the probability that we get a connected graph if we are given that the outcome is a bipartite graph? 

\begin{definition}[{\bf Independent events}]
Two events ${\cal{E}}$ and ${\cal{E}'}$ are said to be \textit{independent}, if 
$$Pr({\cal{E}}|{\cal{E}'}) = Pr({\cal{E}})$$
Equivalently,
$$Pr({\cal{E}} \cap {\cal{E}'}) = Pr({\cal{E}})Pr({\cal{E}}')$$
\end{definition}

For example, if we consider the events event ${\cal{E}}$ represent the set of connected graphs and event ${\cal{E}'}$ represent the set of bipartite graphs, then:
$$Pr({\cal{E}} \cap {\cal{E}'}) = 3p^2(1-p)$$
$$Pr({\cal{E}})Pr({\cal{E}'}) = \left[(1-p)^3+3p(1-p)^2+3p^2(1-p)\right](1-p^3)$$

Since they are not equal, we conclude that the two events are not indendent. That is, the event that the graph is bipartite has an "influence" on the event that the graph is connected. To make this clearer, we suggest the following exercise:

\begin{exercise}
Let $G \in G(n,p)$. For all $S \subseteq V$, let $A_S$ be the event that $S$ forms an independent set in $G$. Show that if $S$ and $T$ are two distinct subsets of $k$ vertices then $A_S$ and $A_T$ are independent if and only if
$|S \cap T| \le 1$.
\end{exercise}

\noindent Now, we will generalize the above notion of independence to more than two events. An event $\calE$ is independent of a set of events
$\{ \calE_j \mid j \in J\}$ if, for all subset $J' \subseteq J$, 
$Pr [ \calE | \cap_{j \in J} B_j ] = Pr(A)$.

\begin{exercise}
Prove that an event $\calE$ is independent of a set of events $\{ \calE_j \mid j \in J\}$ 
if and only if for all $J_1, J_2 \subseteq J$
such that $J_1 \cap J_2 = \phi$
$$\Pr [ \calE \cap \left( \cap_{j \in J_1} B_j \right) \cap \left( \cap_{j \in J_2} \overline{B_j} \right) ] = \Pr(\calE) \Pr[\left( \cap_{j \in J_1} B_j \right) \cap \left( \cap_{j \in J_2} \overline{B_j} \right) ]$$
\end{exercise}

Let $\{ \calE_i \mid i \in I \}$ be a (finite) set of events. They are \textit{pairwise independent} if for all $i \ne j$ the events $\calE_i$ and $\calE_j$ are independent. Events are \textit{mutually independent} if each of them is independent from the set of the others. It is important to note that events may be pairwise independent but not mutually independent. Following exercise demonstrates that.

\begin{exercise-prob}[See Problem Set 1(Problem~\ref{independence})]
\begin{show-ps1}{independence}
A random $k$-colouring fo a graph $G$ is an element of the probability space $(\Omega,Pr)$
where $\Omega$ is the set of all $k$-colourings (i.e. partition of $V$ into $k$ sets ($V_1,V_2,\ldots,V_k$), all this colourings being equally likely (so happening with probability $\frac{1}{k^n}$. For every edge $e$ of $G$, let $A_e$ be the event that the two endvertices of e receive the same colour. Show that:
\begin{enumerate}[(a)]
\item for any two edges e and f of G, the events $A_e$ and $A_f$ are independent.
\item if $e,f$ and $g$ are three edges of a triangle of $G$, the events $A_e$, $A_f$ and $A_g$ are dependents.
\end{enumerate}
\end{show-ps1}
\end{exercise-prob}

\paragraph*{Random Variables:}
We need the idea of random variables which we recap now. A random variable is another function $X : \Omega \to \mathbb{R}$. The expected value of the random variable is the "weighted average" value that it takes over the real numbers - weighted by the correspoding probability values. That is, 
$$ E[X] = \bigsum_{\alpha \in \mathbb{R}} \alpha \Pr[X = \alpha]$$
Indeed, $[X = \alpha]$ represents an event $\{ w \in \Omega \mid X(w) = \alpha \} \subseteq \Omega$. Hence, the expectation can also be written equivalently as follows:
$$E[X] = \bigsum_{\alpha \in \mathbb{R}} \alpha \left( \bigsum_{\substack{w \in \Omega \\ X(w) = \alpha}} \Pr(w) \right)  = \bigsum_{w \in \Omega} X(w)\Pr(w)$$

We need the following properties of expectation:
\begin{description}
\item{\bf Tool 1 : Boolean Random Variables } - 
Suppose $X$ is a random variable that takes only Boolean values. In this case, $E[X] = \Pr[X=1]$ which follows from the definitions.
\item{\bf Tool 2 : Linearity of Expectation }: Suppose $X_1$ and $X_2$ are random variables defined based on the same probability distribution, consider the new random variable defined as $X = c_1X_1 + c_2X_2$. This is also a random variable as it is a function from $\Omega \to \mathbb{R}$ defined as $X(w) = c_1X_1(w)+c_2X_2(w)$ for every $w \in \Omega$. It turns out there is a neat relationship between the expectation of the random variables $X, X_1$ and $X_2$. This is one of the most imporant relation that is extensively used in analysis of randomized algorithms.
\begin{eqnarray*}
E[X] & = & \sum_{w \in \Omega} X(w)\Pr(w) = \sum_{w \in \Omega} \left( c_1X_1(w)+c_2X_2(2) \right) \Pr(w) \\
& = & c_1 \left( \sum_{w \in \Omega} X_1(w)\Pr(w)  \right)  + c_2 \left( \sum_{w \in \Omega} X_2(w) \Pr(w) \right)
= c_1E[X_1]+c_2E[X_2]
\end{eqnarray*}

We suggest practicing the application of linearity of expectation using the following exercise.
\begin{exercise-prob}[See Problem Set 1(Problem~\ref{spanning-trees})]
\begin{show-ps1}{spanning-trees}
A graph $G=(V,E)$ is created at random by selecting each edge with probability $p$.  What is the expected number of spanning trees in the randomly sampled graph?
(\textit{Hint : Use Cayleyâ€™s Theorem that the number of distinct spanning trees on $n$ vertices is $n^{n-2}$. Order them, and define an indicator random variable.})

\end{show-ps1}
\end{exercise-prob}

\item{\bf Tool 3 : Averaging Principle } - 
Suppose $X$ is a random variable and $E[X] = \mu$, then the following statements follow:
$$\exists w \in \Omega : X(w) \ge \mu \hspace{1cm} \exists w \in \Omega : X(w) \le \mu$$
Both of them can be proved by contradiction. For sample, we spell out the first one, suppose that the first statement is false. That is, $\forall w \in \Omega, X(w) < \mu$, then:
$$E[X] = \bigsum_{w \in \Omega} X(w) \Pr(w) < \bigsum_{w \in \Omega} \left( \mu \times  \Pr(w) \right) = \mu \left( \bigsum_{w \in \Omega} \Pr(w) \right) = \mu$$
This implies, $E[X] < \mu$ which is a contrdiction. A similar proof holds for the other claim as well.
\item{\bf Tool 4 : Tail inequalities} - Suppose we have a random variable $X$ such that $E[X] = \mu$. What kind of probability guarantees can we write for $X$? For example, can we bound (in terms of the expectation) the probability that $X > \alpha$ for some $\alpha \in \mathbb{R}$? This is what tail bounds do. They help us write probability upper bounds based on expectations and other related parameters. 

As a first example, consider a random variable that takes only non-negative values. Then we can write :
$$\textrm{\bf Markov's Inequality : } \Pr[X \ge a] \le \frac{E[X]}{a}$$
The proof is also quite simple.
$$
E[X] = \bigsum_{\alpha \in \mathbb{R}} \alpha \Pr[X=\alpha] 
\ge \bigsum_{\alpha \ge a} \alpha \Pr[X=\alpha] \ge 
\bigsum_{\alpha \ge a} a \Pr[X=\alpha] \ge 
a \Pr[X \ge a]$$

For example, this helps us make statements of the form :
$$\Pr[X > 4\mu] \le \frac{\mu}{4\mu} = \frac{1}{4}$$
That is the probability that the random variable takes a value which is more than $4$ times the expected value is at most $0.25$. Unfortunately, this does not help us write down a probability bound for $X$ taking value less than say $\frac{\mu}{4}$. Indeed, Markov's inequality is also pretty weak - as demonstrated by the following example - consider tossing $n$ coins and $X$ be the number of heads. Clearly $E[X] = \frac{n}{2}$. By Markov's inequality, $\Pr[X \ge n] \le \frac{1}{2}$ but we know that it is much smaller than that, namely $\frac{1}{2^n}$.

What do we want if we want to bound the probability that the random variable takes a much lower value than the expectation? This is where we require more the next tail bound (without any assumptio of positivity on the random variable).
$$\textrm{\bf Chebychev's Inequality : } \Pr[|X-\mu| \ge a] \le \frac{Var[X]}{a^2} \textrm{ where, $Var[X] = E[X^2] - E[X]^2$} $$
We will not discuss the proof of Chebychev's inequality since we do not require it immediately. This concludes the review.
\end{description}

\section{Analysis of the Algorithm for {\sc Maxcut}}
Recall Algorithm~\ref{alg:maxcut-rand}. We want to guarantee that th expected size of the cut is at most half of the optimal cut size. In fact, we prove something stronger.
\begin{claim}
Let $X$ be the size of the cut output by the algorithm~\ref{alg:maxcut-rand}. Then, $E[X] \ge \frac{m}{2}$ where $m$ is the number of edges in the graph $G$.
\end{claim}
\begin{proof}
For each edge $e \in E$ define a random variable $X_e$ as the following indicator variable:
$$ X_e = \begin{cases} 1 & \textrm{ if $e \in cut(S,T)$ } \\
0 & \textrm{ otherwise } \end{cases} $$
By definition, $X = \sum_{e \in E} X_e$. Hence, by linearity of expectation:
$$E[X] = \sum_{e \in E} E[X_e] = m E[X_e]$$
We just need to notice that $E[X_e] = \Pr[X_e = 1] = \Pr[e \in cut(S,T)]$ because of tool 1. Notice that an edge $e$ is in the cut if the two end points get into different sets among $S$ and $T$. That is, out of the four possible outcomes of the random coin tosses correspnoding to the endpoint vertices of $e$, two of them leads to $e$ being in $cut(S,T)$. Hence this is exactly $\half$. This gives:
$E[X] \ge \frac{m}{2}$. Hence the proof.
\end{proof}
Notice that the claim is stronger. Indeed, since the optimum cut can only cut at most $m$ edges, the above also implies $E[X] \ge \frac{m}{2} \ge \frac{\textrm{\sc OptCut}}{2}$.

\section{Method of Conditional Expectations}

We now describe the main technical idea to be learned this week. Mainly an algorithm specific technique of derandomization of randomized algorithms. This presentation is from Salil Vadhan's book on Pseudorandomness.

There are two kinds of randomized algorithms that we have seen so far - essentially to solve two kinds of problems. One is for the decision problems where the probability over different paths of the  computation tree, the algorithm being correct is at least $\frac{2}{3}$. The other is for optimization problems where the expected size of the output has guarantees. The method of derandomization that we are going to discuss can in principle be applied for both, if the randomized algorithm in question uses the random bits in a peculiar way that certain measures can be computed efficiently about the output for particular settings of the randomness. \\[-8mm]

\paragraph{Main Idea:} We discuss the first kind of algorithms first and then adapt it to the second type. In the decision problem case, we know that $\frac{2}{3}$-rd paths in the computation tree are going to make the algorithm answer correctly. A vague idea would be, is there a way to walk down the path of the tree, making a choice deterministically and efficiently at each node (without trying both choices which leads to exponential time) maintaining the invariant that within the subtree that have restricted ourselves to, a $\frac{2}{3}$ fraction of paths within the subtree still make the algorithm go correct. If we make choices like this and set the random bits based on that choices, it is intuitive that we will reach a leaf that makes the algroithm answer correctly and then we can just run the algorithm on that leaf (that choice of random bits) and output the answer. The process is deterministic and effcient and hence gives a derandomization of the original algorithm.

Of course, this is easier said than done. Many questions remain.